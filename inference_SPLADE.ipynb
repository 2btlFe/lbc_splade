{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ac4e511-5d44-4c08-a57b-8772b0a3f4ba",
   "metadata": {},
   "source": [
    "# SPLADE: Sparse Lexical and Expansion Model for First Stage Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5133de-c802-4669-ae18-3d99c8d3b197",
   "metadata": {},
   "source": [
    "This notebook gives a minimal example usage of our SPLADE model. In a nutshell, SPLADE learns **sparse**, **expansion-based** query/doc representations for efficient first-stage retrieval.\n",
    "\n",
    "Sparsity is induced via a regularization applied on representations, whose strength can be adjusted; it is thus possible to control the trade-off between effectiveness and efficiency. For more details, check our paper, and don't hesitate to reach out ! \n",
    "\n",
    "We provide weights for two models (in the `weights` folder):\n",
    "\n",
    "| model | MRR@10 (MS MARCO dev) | recall@1000 (MS MARCO dev) | expected FLOPS | ~ avg q length | ~ avg d length | \n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| `flops_best` | 32.2 | 95.5 | 0.73 | 15 | 58 |\n",
    "| `flops_efficient` | 29.6 | 93.3 | 0.05 | 6 | 18 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03e94b11-ee3c-454d-8858-15b8615a7017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "649a7a51-32c5-4e86-921f-cf12b498e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Splade(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, model_type_or_dir):\n",
    "        super().__init__()\n",
    "        self.transformer = AutoModelForMaskedLM.from_pretrained(model_type_or_dir)\n",
    "    \n",
    "    def forward(self, **kwargs):\n",
    "        out = self.transformer(**kwargs)[\"logits\"] # output (logits) of MLM head, shape (bs, pad_len, voc_size)\n",
    "        return torch.sum(torch.log(1 + torch.relu(out)) * kwargs[\"attention_mask\"].unsqueeze(-1), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09cd4b0d-8cc6-4f71-a793-9d8fd4515bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the dir for trained weights \n",
    "\n",
    "model_type_or_dir = \"weights/flops_efficient\"\n",
    "# model_type_or_dir = \"weights/flops_best\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70bdc9ad-5f9e-4682-81ea-dce6c8f255a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading model and tokenizer\n",
    "\n",
    "model = Splade(model_type_or_dir)\n",
    "model.eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_type_or_dir)\n",
    "reverse_voc = {v: k for k, v in tokenizer.vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "988f0e04-a323-498b-b3ec-8b2e0e0cd0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example document from MS MARCO passage collection (doc_id = 8003157)\n",
    "\n",
    "doc = \"Glass and Thermal Stress. Thermal Stress is created when one area of a glass pane gets hotter than an adjacent area. If the stress is too great then the glass will crack. The stress level at which the glass will break is governed by several factors.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b62be12-d956-4fda-a21f-3085fa9ce0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of actual dimensions:  15\n",
      "SPLADE BOW rep:\n",
      " [('glass', 2.22), ('stress', 2.19), ('thermal', 1.91), ('pan', 1.6), ('crack', 1.1), ('created', 0.98), ('caused', 0.77), ('hotter', 0.58), ('adjacent', 0.36), ('create', 0.35), ('area', 0.34), ('break', 0.3), ('plastic', 0.29), ('shatter', 0.11), ('hot', 0.09)]\n"
     ]
    }
   ],
   "source": [
    "# now compute the document representation\n",
    "with torch.no_grad():\n",
    "    doc_rep = model(**tokenizer(doc, return_tensors=\"pt\")).squeeze()  # (sparse) doc rep in voc space, shape (30522,)\n",
    "\n",
    "# get the number of non-zero dimensions in the rep:\n",
    "col = torch.nonzero(doc_rep).squeeze().cpu().tolist()\n",
    "print(\"number of actual dimensions: \", len(col))\n",
    "\n",
    "# now let's inspect the bow representation:\n",
    "weights = doc_rep[col].cpu().tolist()\n",
    "d = {k: v for k, v in zip(col, weights)}\n",
    "sorted_d = {k: v for k, v in sorted(d.items(), key=lambda item: item[1], reverse=True)}\n",
    "bow_rep = []\n",
    "for k, v in sorted_d.items():\n",
    "    bow_rep.append((reverse_voc[k], round(v, 2)))\n",
    "print(\"SPLADE BOW rep:\\n\", bow_rep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
